{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark-study",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMAWkuXnVrFRw7vgo6eswuw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuplamenteH/Ds_estudos/blob/main/pyspark_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NioqJuE8zf9m"
      },
      "source": [
        "## instalação do pyspark no colab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E84-KusQ-isn"
      },
      "source": [
        "para instalar o pyspark primeiro teremos que instalar  -> java , spark\n",
        "configurar java_home, e spark_home, instalar o findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfhYta8e_8d-"
      },
      "source": [
        "instalação de configuração das variaveis de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JofZ5SXlzI3G"
      },
      "source": [
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d47dMR9MA6wW"
      },
      "source": [
        "import findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPKmBu4GABch"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n",
        " \n",
        "# tornar o pyspark \"importável\"\n",
        "#import findspark\n",
        "findspark.init('spark-3.0.1-bin-hadoop2.7')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importação"
      ],
      "metadata": {
        "id": "ig8pGhh_VaI2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwjKVJY3CHMc"
      },
      "source": [
        "Depois de importado e configurado vamos dar inicio ao spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ieIx_WaCWNp"
      },
      "source": [
        "importaremos sparkSession para inicio a nossa sessão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi0Kg6D2Aydv"
      },
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE3ACaSQCVI-"
      },
      "source": [
        "spark = SparkSession.builder.appName(\"Data_Wrangling\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccV9tHHRGPLz"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/Apress/applied-data-science-using-pyspark/main/Ch02/Chapter2_Data/movie_data_part1.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4eCKz4iEMzD"
      },
      "source": [
        "dados = 'movie_data_part1.csv'\n",
        "file_type = \"csv\"\n",
        "infer_schema = \"False\"\n",
        "first_row_is_header = \"True\"\n",
        "delimiter  = \"|\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrfY9gUKGwV8"
      },
      "source": [
        "primeira forma de carregar os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94DBUnc3ErC8"
      },
      "source": [
        "df = spark.read.format(file_type)\\\n",
        ".option(\"inferSchema\",infer_schema)\\\n",
        ".option(\"header\",first_row_is_header)\\\n",
        ".option(\"sep\",delimiter)\\\n",
        ".load(dados)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj7AfpyQG0dA"
      },
      "source": [
        "## Lendo os dados de uma tabela hive\n",
        "\n",
        "\n",
        "df2 = spark.sql(\"select * from database.table_name\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wiKBH_WHN9z"
      },
      "source": [
        "printamos os schema, assim podemos ver as colunas, se existem valores faltantes, e o tipo de cada coluna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32WyRIu0HA13"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV9U2xCfHhDg"
      },
      "source": [
        "com a função df.dtypes, retornamos uma lista de tuplas com o nome da coluna e o tipo da coluna apenas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFgJ3mbaHKnS"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fR1v7ULHsHA"
      },
      "source": [
        "agr vamos saber o tamanho desse dataset, quantas linha tem o mesmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_MyUosfHcs0"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUxjXVBaH0Kp"
      },
      "source": [
        "uma maneira mai bonita seria assim:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hapVd0RXHzCx"
      },
      "source": [
        "print(\"O total dos nossos registros é de  : {}\".format(df.count()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzBHDFycIi3Q"
      },
      "source": [
        "Coletando subcolunas para ter uma visão geral dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJeA20XIH2r"
      },
      "source": [
        "select_columns = ['id', 'budget', 'popularity', 'release_date',\n",
        "                  'revenue', 'title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08WeikyaJBel"
      },
      "source": [
        "df =df.select(*select_columns)\n",
        "df.show(30,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FudZKVAjMD3u"
      },
      "source": [
        "## Valores faltantes do nosso dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH5zXjbtMHN-"
      },
      "source": [
        "algumas maneiras de calcular os valores faltantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpLu-9WSJDYx"
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taeu3JefMTUa"
      },
      "source": [
        "df.filter((df['popularity']=='')|df['popularity'].isNull()|isnan(df['popularity'])).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqfNAotfMtcG"
      },
      "source": [
        "na operação usando o condicional OR -> |,\n",
        "\n",
        "na primeira condição achamos as strings nulas presentes em popularity comparando com strings vazias, na segunda condição chamamos a função .isNull() para a colunar popularity que retorna true quando alguma linha popularity é verdadeira e false se o contrario acontecer, na terceira condição usando a função isnan()-> not a number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SIHSsLTNpRV"
      },
      "source": [
        "A segunda forma de achar a quantidade de valores faltantes é da seguinte forma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk1SiMgzMqBq"
      },
      "source": [
        "df.select([count(when((col(c)=='')| col(c).isNull()|isnan(c),c)).\n",
        "           alias(c) for c in df.columns]).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOEQ46I6ObsF"
      },
      "source": [
        "One-Way-Frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV9e-DZfmZO4"
      },
      "source": [
        "Agr vamos calcular as frequencias do nosso dataset, vamos verificar abaixo os titulos refletidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqCcoXyjOG9T"
      },
      "source": [
        "df.groupBy(df['title']).count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1euxg-hm3P7"
      },
      "source": [
        "Bom agr vamos ordenar nossas frenquencia para exibir as 10 maiores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cATjioPLmuU3"
      },
      "source": [
        "df.groupby(df['title']).count().sort(desc(\"count\")).show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccnT6oAqoKyb"
      },
      "source": [
        "ordenando e filtrando nossas one-way frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5oMTRBsoWy8"
      },
      "source": [
        "1º. Vamos criar um dataset temporario para eliminar os valores faltantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3fIHAelnOrA"
      },
      "source": [
        "df_temp = df.filter((df['title']!='')&(df['title'].isNotNull())&(~isnan(df['title'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffZBJ4d3pCEr"
      },
      "source": [
        "verificando nosso datafreme temporario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cikl2kv1o3dY"
      },
      "source": [
        "df_temp.groupby(df_temp['title']).count().filter(\"`count`>4\").sort(col(\"count\").desc()).show(20,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfST9S2ipiW8"
      },
      "source": [
        "Vemos na tabela acima que os dados faltantes foram eliminados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g1oaghepxg4"
      },
      "source": [
        "No código abaixo vamos mostrar os titulos que são repetidos mais de 4 vezes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0xyUiK5pfVH"
      },
      "source": [
        "df_temp.groupby(df_temp['title']).count().filter(\"`count`>=4\").sort(col(\"count\").desc()).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fTmSlqnrPsy"
      },
      "source": [
        "Agr vamos deletar o dataframe temporario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRoz4SOPrNjM"
      },
      "source": [
        "del df_temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv06sDaMrZ5D"
      },
      "source": [
        "Casting Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8UlJKxcruwy"
      },
      "source": [
        "Antes do casting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDTeki2UqWGn"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8LnRXdnryU8"
      },
      "source": [
        "df = df.withColumn('budget',df['budget'].cast(\"float\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh7vVBQar8kq"
      },
      "source": [
        "depois do casting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2OXZ2psr76z"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGTxGPg9sVyV"
      },
      "source": [
        "Agora vamos usar outro método para fazer o casting, vamos fazer um loop pela coluna que queremos mudar seu tipo e ai sim fazer a mudança"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFdKaeANr___"
      },
      "source": [
        "from pyspark.sql.types import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4ajkMy1s9VF"
      },
      "source": [
        "selecionando as colunas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2-routFsohe"
      },
      "source": [
        "int_var = ['id']\n",
        "float_vars = ['budget', 'popularity', 'revenue']\n",
        "date_vars = ['release_date']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnLA5Rpas7Qi"
      },
      "source": [
        "fazendo a conversão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvBei21Rs5vd"
      },
      "source": [
        "for column in int_var:\n",
        "    df = df.withColumn(column,df[column].cast(IntegerType()))\n",
        "\n",
        "for column in float_vars:\n",
        "    df = df.withColumn(column,df[column].cast(FloatType()))\n",
        "\n",
        "for column in date_vars:\n",
        "    df = df.withColumn(column,df[column].cast(DateType()))\n",
        "\n",
        "\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPQ59X91tnv1"
      },
      "source": [
        "mostrando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI8N0RT9tjjS"
      },
      "source": [
        "df.show(20,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so18ya3_uI75"
      },
      "source": [
        "## Estatisticas Descritivas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUPzBSjrtr5b"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jknPkWZ-wInp"
      },
      "source": [
        "Retirando os valores 0 do budget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcHo2TIruN94"
      },
      "source": [
        "df_temp = df.filter((df['budget']!=0)&(df['budget'].isNotNull())&(~isnan(df['budget'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMeQkutuws51"
      },
      "source": [
        "verificando se deu certo nossa operação de remover os falores faltantes do nosso df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzyTd99Uwqfb"
      },
      "source": [
        "df_temp.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoG7K-Msxh7c"
      },
      "source": [
        "calculando e ajustando a media\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCjiGZJSw0np"
      },
      "source": [
        "median = df_temp.approxQuantile('budget',[0.5],0.1)\n",
        "\n",
        "print('A media do budget é '+str(median))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjGWFchnyjqg"
      },
      "source": [
        "Valores unicos/distintos e counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nsp9m3wyzFA"
      },
      "source": [
        "contando os titulos distintos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSMz4Hy1x_Ju"
      },
      "source": [
        "df.agg(countDistinct(col('title')).alias(\"count\")).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlhaSo7Rzzcw"
      },
      "source": [
        "Contando os titulos distintos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9NaU2kFy7gb"
      },
      "source": [
        "df.select('title').distinct().show(20,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCBg0nUu0L0g"
      },
      "source": [
        "Bom, seria uma boa identificar os titulos distintos por ano de lançamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU35ayPV0UHn"
      },
      "source": [
        "vamos extrair o ano da nossa coluna realease date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejg3AC_xz_Oi"
      },
      "source": [
        "df_date = df.withColumn('release_year', year('release_date'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ1LzFt50spM"
      },
      "source": [
        "com isso tbm conseguimos extrair os meses e os dias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJyiC2-V0lCd"
      },
      "source": [
        "df_date = df_date.withColumn('release_month', month('release_date'))\n",
        "df_date = df_date.withColumn('release_day', dayofmonth('release_date'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUjH6tJ61PV1"
      },
      "source": [
        "calculando os dados distintos por ano\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AedjYzsp1Om7"
      },
      "source": [
        "df_date.groupBy(\"release_year\").agg(countDistinct(\"title\")).show(40,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLwGZf0K2zIi"
      },
      "source": [
        "## Filtering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "semelhante ao metodo **where** , o metodo filter serve para realizar buscas dentro da nossa base de dados."
      ],
      "metadata": {
        "id": "0HcIWm5R5Yfk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATdwo3oU1egr"
      },
      "source": [
        "df.filter(df['title'].like('Meet%')).show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#titulos que não terminam com a letra \"S\"\n",
        "\n",
        "df.filter(~df['title'].like('%s')).show(10,False)"
      ],
      "metadata": {
        "id": "VjsKb66Y6Q06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filmes onde a contem a palavra over\n",
        "df.filter(df['title'].rlike('\\w*ove')).show(10,False)"
      ],
      "metadata": {
        "id": "6cqeDbAq6nii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#outro modo de escrever\n",
        "df.filter(df.title.contains('over')).show()"
      ],
      "metadata": {
        "id": "cu_9T8s369nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identificando os filmes que iniciam com \"re\"\n",
        "df.select(df.colRegex(\"`re\\w*`\")).printSchema()\n"
      ],
      "metadata": {
        "id": "duexd9K57NKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.colRegex(\"`\\w*e`\")).printSchema()"
      ],
      "metadata": {
        "id": "8-c0sF0u7hzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O que é regex?\n",
        "<br/> De maneira geral usamos regex para identicar todos os carecteres e numeros de um \"texto\".\n",
        "\n",
        "* \\d -> Identifica numeros entre 0 e 9\n",
        "* \\w -> Identifica todos o caractres maiusculos e minusculos do alfabeto e numero de 0 a 9 [A-Z, a-z, ,0-9] \n",
        "* \\s - Espaços em branco\n",
        "* . Todo caractere\n",
        "\n",
        "também podemos usar isso de maneira quantitativa:\n",
        "*   *_=> 0 ou mais caracteres\n",
        "*   +_=> 1 ou mais caracteres\n",
        "* {min,max} - especificar o tamanho dos caracteres\n",
        "* {n} - numero exato dos n caracteres\n"
      ],
      "metadata": {
        "id": "rhkO8G9Z8bbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criando novas colunas\n"
      ],
      "metadata": {
        "id": "rhrIW7UGKtLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria novas features (colunas) é algo que acontece em qualquer projeto de data science, o spark oferece diversos meios para isso acontecer, um metodo simples seria usar o \"withColumn\". Vamos calcular a variancia da popularidade dos nossos filmes, variancia indica o quanto os numeros estão distantes da media.\n",
        "\n",
        "$ s^2 = Σ(X_i - \\bar{X})^2 / (n-1)$"
      ],
      "metadata": {
        "id": "daON4Z7QKyf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_pop = df.agg({'popularity': 'mean'}).collect()[0]['avg(popularity)']\n",
        "count_obs = df.count()"
      ],
      "metadata": {
        "id": "Hn1ym3SV8UF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('mean_popularity', lit(mean_pop))"
      ],
      "metadata": {
        "id": "2sP3Hj08OfQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('variance',pow((df['popularity'] - df['mean_popularity']),2))"
      ],
      "metadata": {
        "id": "dnc5LEgXOt9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variance_sum = df.agg({'variance':'sum'}).collect()[0]['sum(variance)']\n",
        "\n",
        "variance_population = variance_sum/(count_obs-1)\n",
        "\n"
      ],
      "metadata": {
        "id": "BetOANBvO86M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Variancia = {}\".format(variance_population))"
      ],
      "metadata": {
        "id": "-u4pXzpwPgay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_cols(budget, popularity):\n",
        "    if budget < 10000000: budget_cat = 'Small'\n",
        "    elif budget < 100000000: budget_cat = 'Medium'\n",
        "    else: budget_cat = 'Big'\n",
        "    if popularity < 3: ratings = 'Low'\n",
        "    elif popularity < 5: ratings = 'Mid'\n",
        "    else: ratings = 'High'\n",
        "    return budget_cat, ratings"
      ],
      "metadata": {
        "id": "hQ2E_JdxP1MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pesquisar melhor o metodo  StructType\n",
        "ufdB = udf(new_cols, StructType([StructField(\"budget_cat\",StringType(),True), StructField(\"ratings\",StringType(),True)]))\n",
        "\n",
        "temp_df = df.select('id','budget','popularity').withColumn(\"newcat\",ufdB(\"budget\",\"popularity\"))\n",
        "\n",
        "df_with_newcols = temp_df.select('id','budget','popularity','newcat')\\\n",
        ".withColumn('budget_cat',temp_df.newcat.getItem('budget_cat'))\\\n",
        ".withColumn('ratings',temp_df.newcat.getItem('ratings'))\\\n",
        ".drop('newcat')\n"
      ],
      "metadata": {
        "id": "OyYcxLF-P1Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_newcols.show(15,False)"
      ],
      "metadata": {
        "id": "Y3f0GXpcP06Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazer o exercicio da pagina 80"
      ],
      "metadata": {
        "id": "hWA2tqp3VPF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w6hObwynU_aO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}